INFO:torchtune.utils.logging:Logging /home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/.checkpoints/original/torchtune_config.yaml to W&B under Files
INFO:torchtune.utils.logging:Model is initialized with precision torch.bfloat16.
INFO:torchtune.utils.logging:Memory Stats after model init:
{'peak_memory_active': 16.572998144, 'peak_memory_alloc': 16.572998144, 'peak_memory_reserved': 16.642998272}
INFO:torchtune.utils.logging:Tokenizer is initialized from file.
INFO:torchtune.utils.logging:Optimizer and loss are initialized.
INFO:torchtune.utils.logging:Loss is initialized.
INFO:torchtune.utils.logging:Dataset and Sampler are initialized.
INFO:torchtune.utils.logging:Learning rate scheduler is initialized.
1|1|Loss: 2.0842018127441406: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.11it/s]
Traceback (most recent call last):
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/bin/tune", line 8, in <module>
    sys.exit(main())
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/torchtune/_cli/tune.py", line 49, in main
    parser.run(args)
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/torchtune/_cli/tune.py", line 43, in run
    args.func(args)
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/torchtune/_cli/run.py", line 179, in _run_cmd
    self._run_single_device(args)
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/torchtune/_cli/run.py", line 93, in _run_single_device
    runpy.run_path(str(args.recipe), run_name="__main__")
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/recipes/lora_finetune_single_device.py", line 510, in <module>
    sys.exit(recipe_main())
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/torchtune/config/_parse.py", line 50, in wrapper
    sys.exit(recipe_main(conf))
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/recipes/lora_finetune_single_device.py", line 505, in recipe_main
    recipe.train()
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/recipes/lora_finetune_single_device.py", line 487, in train
    self.save_checkpoint(epoch=curr_epoch)
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/recipes/lora_finetune_single_device.py", line 395, in save_checkpoint
    merged_state_dict = get_merged_lora_ckpt(
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/torchtune/modules/peft/peft_utils.py", line 256, in get_merged_lora_ckpt
    state_dict[f"{module}.weight"] += (alpha / rank) * lora_b_weight @ lora_a_weight
KeyboardInterrupt