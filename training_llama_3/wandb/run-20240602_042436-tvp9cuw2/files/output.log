INFO:torchtune.utils.logging:Logging /home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/.checkpoints/original/torchtune_config.yaml to W&B under Files
INFO:torchtune.utils.logging:Model is initialized with precision torch.bfloat16.
INFO:torchtune.utils.logging:Memory Stats after model init:
{'peak_memory_active': 16.572998144, 'peak_memory_alloc': 16.572998144, 'peak_memory_reserved': 16.642998272}
INFO:torchtune.utils.logging:Tokenizer is initialized from file.
INFO:torchtune.utils.logging:Optimizer and loss are initialized.
INFO:torchtune.utils.logging:Loss is initialized.
INFO:torchtune.utils.logging:Dataset and Sampler are initialized.
INFO:torchtune.utils.logging:Learning rate scheduler is initialized.


















































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































1|6330|Loss: 1.0059027671813965: 100%|██████████████████████████████████████████████████████████████████| 6330/6330 [40:05<00:00,  2.63it/s]
INFO:torchtune.utils.logging:Model checkpoint of size 16.06 GB saved to /home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/.checkpoints/llama3/meta_model_0.pt
INFO:torchtune.utils.logging:Adapter checkpoint of size 0.01 GB saved to /home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/.checkpoints/llama3/adapter_0.pt
INFO:torchtune.utils.logging:Recipe checkpoint of size 0.01 GB saved to /home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/.checkpoints/llama3/recipe_state.pt

















































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































2|6330|Loss: 1.0061379671096802: 100%|██████████████████████████████████████████████████████████████████| 6330/6330 [40:03<00:00,  2.63it/s]
INFO:torchtune.utils.logging:Model checkpoint of size 16.06 GB saved to /home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/.checkpoints/llama3/meta_model_1.pt
INFO:torchtune.utils.logging:Adapter checkpoint of size 0.01 GB saved to /home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/.checkpoints/llama3/adapter_1.pt
INFO:torchtune.utils.logging:Recipe checkpoint of size 0.01 GB saved to /home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/.checkpoints/llama3/recipe_state.pt

















































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































3|6330|Loss: 0.5625711679458618: 100%|██████████████████████████████████████████████████████████████████| 6330/6330 [40:03<00:00,  2.63it/s]
INFO:torchtune.utils.logging:Model checkpoint of size 16.06 GB saved to /home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/.checkpoints/llama3/meta_model_2.pt
INFO:torchtune.utils.logging:Adapter checkpoint of size 0.01 GB saved to /home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/.checkpoints/llama3/adapter_2.pt
INFO:torchtune.utils.logging:Recipe checkpoint of size 0.01 GB saved to /home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/.checkpoints/llama3/recipe_state.pt


















































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































4|6330|Loss: 1.3780227899551392: 100%|██████████████████████████████████████████████████████████████████| 6330/6330 [40:08<00:00,  2.63it/s]
INFO:torchtune.utils.logging:Model checkpoint of size 16.06 GB saved to /home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/.checkpoints/llama3/meta_model_3.pt
INFO:torchtune.utils.logging:Adapter checkpoint of size 0.01 GB saved to /home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/.checkpoints/llama3/adapter_3.pt