INFO:torchtune.utils.logging:Logging /home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/.checkpoints/original/torchtune_config.yaml to W&B under Files
INFO:torchtune.utils.logging:Model is initialized with precision torch.bfloat16.
INFO:torchtune.utils.logging:Memory Stats after model init:
{'peak_memory_active': 16.572998144, 'peak_memory_alloc': 16.572998144, 'peak_memory_reserved': 16.642998272}
INFO:torchtune.utils.logging:Tokenizer is initialized from file.
INFO:torchtune.utils.logging:Optimizer and loss are initialized.
INFO:torchtune.utils.logging:Loss is initialized.
INFO:torchtune.utils.logging:Dataset and Sampler are initialized.
INFO:torchtune.utils.logging:Learning rate scheduler is initialized.

































































































1|366|Loss: 1.8337044715881348:   9%|█████▉                                                              | 365/4220 [03:15<34:21,  1.87it/s]
Traceback (most recent call last):
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/bin/tune", line 8, in <module>
    sys.exit(main())
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/torchtune/_cli/tune.py", line 49, in main
    parser.run(args)
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/torchtune/_cli/tune.py", line 43, in run
    args.func(args)
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/torchtune/_cli/run.py", line 179, in _run_cmd
    self._run_single_device(args)
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/torchtune/_cli/run.py", line 93, in _run_single_device
    runpy.run_path(str(args.recipe), run_name="__main__")
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/recipes/lora_finetune_single_device.py", line 510, in <module>
    sys.exit(recipe_main())
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/torchtune/config/_parse.py", line 50, in wrapper
    sys.exit(recipe_main(conf))
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/recipes/lora_finetune_single_device.py", line 505, in recipe_main
    recipe.train()
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/recipes/lora_finetune_single_device.py", line 468, in train
    loss.backward()
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.47 GiB. GPU