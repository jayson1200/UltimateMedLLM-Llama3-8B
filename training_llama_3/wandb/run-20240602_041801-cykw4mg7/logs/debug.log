2024-06-02 04:18:01,034 INFO    MainThread:3483206 [wandb_setup.py:_flush():76] Current SDK version is 0.17.0
2024-06-02 04:18:01,034 INFO    MainThread:3483206 [wandb_setup.py:_flush():76] Configure stats pid to 3483206
2024-06-02 04:18:01,034 INFO    MainThread:3483206 [wandb_setup.py:_flush():76] Loading settings from /home/meribejayson/.config/wandb/settings
2024-06-02 04:18:01,034 INFO    MainThread:3483206 [wandb_setup.py:_flush():76] Loading settings from /home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/wandb/settings
2024-06-02 04:18:01,034 INFO    MainThread:3483206 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-06-02 04:18:01,034 INFO    MainThread:3483206 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-06-02 04:18:01,034 WARNING MainThread:3483206 [wandb_setup.py:_flush():76] Could not save program above cwd: /home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/recipes/lora_finetune_single_device.py
2024-06-02 04:18:01,034 INFO    MainThread:3483206 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': None, 'program_abspath': '/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/recipes/lora_finetune_single_device.py', 'program': '/home/meribejayson/anaconda3/envs/cs224n-proj/lib/python3.9/site-packages/recipes/lora_finetune_single_device.py'}
2024-06-02 04:18:01,034 INFO    MainThread:3483206 [wandb_setup.py:_flush():76] Applying login settings: {}
2024-06-02 04:18:01,034 INFO    MainThread:3483206 [wandb_init.py:_log_setup():520] Logging user logs to /home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/wandb/run-20240602_041801-cykw4mg7/logs/debug.log
2024-06-02 04:18:01,034 INFO    MainThread:3483206 [wandb_init.py:_log_setup():521] Logging internal logs to /home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/wandb/run-20240602_041801-cykw4mg7/logs/debug-internal.log
2024-06-02 04:18:01,034 INFO    MainThread:3483206 [wandb_init.py:init():560] calling init triggers
2024-06-02 04:18:01,034 INFO    MainThread:3483206 [wandb_init.py:init():567] wandb.init called with sweep_config: {}
config: {}
2024-06-02 04:18:01,034 INFO    MainThread:3483206 [wandb_init.py:init():610] starting backend
2024-06-02 04:18:01,034 INFO    MainThread:3483206 [wandb_init.py:init():614] setting up manager
2024-06-02 04:18:01,034 INFO    MainThread:3483206 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-06-02 04:18:01,035 INFO    MainThread:3483206 [wandb_init.py:init():622] backend started and connected
2024-06-02 04:18:01,036 INFO    MainThread:3483206 [wandb_init.py:init():711] updated telemetry
2024-06-02 04:18:01,049 INFO    MainThread:3483206 [wandb_init.py:init():744] communicating run to backend with 90.0 second timeout
2024-06-02 04:18:01,356 INFO    MainThread:3483206 [wandb_run.py:_on_init():2396] communicating current version
2024-06-02 04:18:01,404 INFO    MainThread:3483206 [wandb_run.py:_on_init():2405] got version response 
2024-06-02 04:18:01,404 INFO    MainThread:3483206 [wandb_init.py:init():795] starting run threads in backend
2024-06-02 04:18:02,328 INFO    MainThread:3483206 [wandb_run.py:_console_start():2374] atexit reg
2024-06-02 04:18:02,328 INFO    MainThread:3483206 [wandb_run.py:_redirect():2229] redirect: wrap_raw
2024-06-02 04:18:02,328 INFO    MainThread:3483206 [wandb_run.py:_redirect():2294] Wrapping output streams.
2024-06-02 04:18:02,328 INFO    MainThread:3483206 [wandb_run.py:_redirect():2319] Redirects installed.
2024-06-02 04:18:02,328 INFO    MainThread:3483206 [wandb_init.py:init():838] run started, returning control to user process
2024-06-02 04:18:02,329 INFO    MainThread:3483206 [wandb_run.py:_config_callback():1376] config_cb None None {'model': {'_component_': 'torchtune.models.llama3.lora_llama3_8b', 'lora_attn_modules': ['q_proj', 'v_proj'], 'apply_lora_to_mlp': False, 'apply_lora_to_output': False, 'lora_rank': 8, 'lora_alpha': 16}, 'tokenizer': {'_component_': 'torchtune.models.llama3.llama3_tokenizer', 'path': '/home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/.checkpoints/original/tokenizer.model'}, 'checkpointer': {'_component_': 'torchtune.utils.FullModelMetaCheckpointer', 'checkpoint_dir': '/home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/.checkpoints/original', 'checkpoint_files': ['consolidated.00.pth'], 'recipe_checkpoint': None, 'output_dir': '/home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/.checkpoints/llama3', 'model_type': 'LLAMA3'}, 'resume_from_checkpoint': False, 'dataset': {'_component_': 'torchtune.datasets.instruct_dataset', 'source': 'szhang120/unified_large_medical_llama3_8b_instruct_dataset', 'train_on_input': True, 'template': 'MedLLMTemplate', 'max_seq_len': 1024, 'load_dataset_kwargs': {'name': 'unified_large_medical_llama3_8b_instruct_dataset', 'split': 'train'}}, 'seed': None, 'shuffle': True, 'batch_size': 3, 'optimizer': {'_component_': 'torch.optim.AdamW', 'weight_decay': 0.01, 'lr': 0.0003}, 'lr_scheduler': {'_component_': 'torchtune.modules.get_cosine_schedule_with_warmup', 'num_warmup_steps': 100}, 'loss': {'_component_': 'torch.nn.CrossEntropyLoss'}, 'epochs': 4, 'max_steps_per_epoch': 128, 'gradient_accumulation_steps': 64, 'compile': False, 'output_dir': '/home/meribejayson/Desktop/Projects/UltimateMedLLM-Llama3-8B/training_llama_3/lora_finetune_out', 'metric_logger': {'_component_': 'torchtune.utils.metric_logging.WandBLogger', 'project': 'CS224n'}, 'log_every_n_steps': None, 'device': 'cuda', 'dtype': 'bf16', 'enable_activation_checkpointing': True, 'profiler': {'_component_': 'torchtune.utils.profiler', 'enabled': False}}
2024-06-02 04:18:09,016 WARNING MsgRouterThr:3483206 [router.py:message_loop():77] message_loop has been closed
